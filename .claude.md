# Gemini Live Avatar - Claude Code Project Instructions

## Project Overview

Voice-to-voice AI avatar application using Google's Gemini 2.5 Flash Live API with native audio and synchronized video playback.

**Tech Stack:**
- Frontend: Vanilla JavaScript, Material Design 3, WebSocket client
- Backend: Python 3.13, asyncio, websockets
- AI: Gemini 2.5 Flash Live (09-2025) with native audio streaming
- Video: State-based avatar (idle, listening, speaking)

---

## üî¥ CRITICAL: ALWAYS USE THIS MODEL

**MODEL NAME (NEVER CHANGE):**
```
models/gemini-2.5-flash-native-audio-preview-09-2025
```

**API TYPE (NEVER CHANGE):**
```
Google AI Developer API (NOT Vertex AI)
Authentication: API Key (NOT Service Account)
API Version: v1alpha
```

**This applies to:**
- All configuration files (.env, config.json)
- All backend code (gemini_client.py, config files)
- All frontend code (gemini-api.js, config.json)
- All test scripts
- All documentation

**No exceptions. No variations. Always this exact model name and API.**

**Critical Details:**
- `models/` prefix REQUIRED for Google AI Developer API (per official Google code)
- Word order: `native-audio-preview` NOT `preview-native-audio`
- For Vertex AI the model is `gemini-live-2.5-flash-preview-native-audio-09-2025` (different!)
- We use Google AI Developer API for simplicity (API key vs service account)

---

## ‚ö†Ô∏è IMPORTANT: Documentation Policy

**DO NOT create summary documents, reports, or wrap-up files for:**
- Code fixes or changes made
- Problems solved
- Issues resolved
- Security patches applied
- Bug fixes completed
- Refactoring work
- Code cleanup
- Testing results

**Examples of documents NOT to create:**
- ‚ùå "FIXES_IMPLEMENTED.md"
- ‚ùå "CHANGES_SUMMARY.md"
- ‚ùå "WORK_COMPLETED.md"
- ‚ùå "ISSUE_RESOLUTION_REPORT.md"
- ‚ùå "CLEANUP_SUMMARY.md"
- ‚ùå Any similar wrap-up documentation

**Why:** The user prefers to track work through git commits and doesn't want summary documents cluttering the project.

**What TO create:**
- ‚úÖ Code files (.js, .py, .html, .css, .json)
- ‚úÖ Configuration files (.env.example, config.json)
- ‚úÖ Test files (test_*.py, *_test.js)
- ‚úÖ Essential documentation (README.md updates if critical)

---

## ‚ö†Ô∏è CRITICAL: SDK Usage Policy

**ONLY use official Google Generative AI SDK methods and patterns.**

### Before Planning ANY Code Change:
1. **ALWAYS check latest SDK references first** (documentation, examples, source code)
2. Verify the method/pattern is officially supported
3. Do not invent custom protocols or workarounds
4. Follow exact SDK patterns from official examples

### Key Findings:
- **Audio transmission:** Reference project sends audio with `end_of_turn=True` immediately
- **Turn signals:** Reference project ignores the "end" signal completely
- **DO NOT** create custom turn-end detection logic if SDK doesn't use it
- **DO NOT** assume SDK features exist without verification

### SDK Reference Sources:

**‚ö†Ô∏è CRITICAL: Two Different APIs with Different Models**

This project uses **Vertex AI** (not Google AI Developer API). The documentation differs significantly:

| Aspect | Vertex AI | Google AI Developer API |
|--------|-----------|-------------------------|
| **Authentication** | Service Account + ADC | API Key |
| **SDK Package** | `google-genai` v1.51.0 | `google-genai` v1.51.0 (same package!) |
| **Live Models** | `gemini-2.0-flash-live-preview-04-09` | `gemini-live-2.5-flash-preview-native-audio-09-2025` |
| **Documentation** | https://googleapis.github.io/python-genai/ | https://googleapis.github.io/python-genai/ |
| **Parameter Style** | **snake_case** (ALWAYS) | **snake_case** (ALWAYS) |
| **MIME Type** | `audio/pcm` OR `audio/pcm;rate=16000` (both work!) | `audio/pcm` OR `audio/pcm;rate=16000` (both work!) |

**Vertex AI SDK Documentation (Use This!):**
- Primary Docs: https://googleapis.github.io/python-genai/
- GitHub: https://github.com/googleapis/python-genai
- PyPI: https://pypi.org/project/google-genai/
- Version: 1.51.0

**Google AI Developer API Docs (Reference Only):**
- Live API: https://ai.google.dev/gemini-api/docs/live
- Python SDK: https://ai.google.dev/gemini-api/docs/python-sdk
- Examples: https://github.com/google-gemini/multimodal-live-api-web-console

**Model Information (Vertex AI Live API):**
- **ONLY Supported Model**: `gemini-2.0-flash-live-preview-04-09` ‚úÖ
- Capabilities: Native audio streaming, multimodal input/output, low latency
- Audio Format: 16kHz PCM16 input, 24kHz PCM16 output

**Models That DON'T Work (Tested 2025-11-18):**
- ‚ùå `gemini-3-pro-preview` - Does not exist in Vertex AI
- ‚ùå `gemini-2.5-flash-native-audio-preview-09-2025` - Google AI Developer API only (not Vertex AI)
- ‚ùå `gemini-2.0-flash-exp` - Exists in Vertex AI but does NOT support Live API (WebSocket error: "not supported in the live api")

**CRITICAL**: Only `gemini-2.0-flash-live-preview-04-09` works with Vertex AI Live API. All other models either don't exist or don't support the Live API.

**If unsure whether a method is official:** Stop and verify against **Vertex AI docs** (googleapis.github.io/python-genai/), not ai.google.dev.

---

## Code Style & Conventions

### JavaScript
- No semicolons (project uses semicolons - follow existing style)
- Use `async/await` for asynchronous operations
- Use `const` and `let`, avoid `var`
- Functions are defined with `function` keyword (not arrow functions for named functions)
- Class-based architecture for managers (AvatarManager, MetricsManager, etc.)

### Python
- Type hints on function signatures
- `async/await` for all WebSocket operations
- f-strings for string formatting
- Descriptive logging with emojis for user-facing messages

### File Organization
```
frontend/
  ‚îú‚îÄ‚îÄ script.js                    # Main orchestration
  ‚îú‚îÄ‚îÄ avatar-manager.js            # Avatar video state management
  ‚îú‚îÄ‚îÄ gemini-live-api.js          # Gemini API client
  ‚îú‚îÄ‚îÄ live-media-manager.js       # Audio/video capture
  ‚îú‚îÄ‚îÄ config-loader.js            # Configuration loader
  ‚îú‚îÄ‚îÄ secure-token-storage.js     # OAuth token storage
  ‚îú‚îÄ‚îÄ *-manager.js                # Other managers
  ‚îî‚îÄ‚îÄ config.json                  # All configuration

backend/
  ‚îî‚îÄ‚îÄ main.py                      # WebSocket proxy server
```

---

## Security Guidelines

### OAuth Tokens
- **NEVER log tokens or token fragments**
- Use `[REDACTED]` in all logs
- Store in `sessionStorage` (not cookies)
- Validate format (`ya29.` prefix)
- Always use `SecureTokenStorage` class

### Input Validation
- Validate all WebSocket messages
- Check message size (1MB max)
- Validate token format before use
- Rate limit: 10 connections/minute per IP
- CORS: Validate origin headers

### Security Checklist
- [ ] No tokens in logs
- [ ] No sensitive data in error messages
- [ ] Use `textContent` not `innerHTML`
- [ ] Validate all user inputs
- [ ] Rate limiting enabled
- [ ] CORS configured

---

## Configuration

All settings centralized in `frontend/config.json`:
- API endpoints and credentials
- Video sources and timing
- Audio settings
- Feature flags
- UI preferences
- Voice and affective dialog settings

**To change settings:** Edit `config.json`, never hardcode values.

### Key Configuration Options:

**Voice Settings** (`geminiVoice`):
```json
"geminiVoice": {
  "enabled": true,
  "voiceName": "Orion",
  "affectiveDialog": true
}
```
- **voiceName**: Choose from Puck, Charon, Kore, Fenrir, Aoede, Zubenelgenubi, Orion, Pegasus, Vega
- **affectiveDialog**: When enabled, Gemini adapts its response style to match input expression and tone (requires API v1alpha)

**Speaking Video Cycle** (`speakingCycle`):
```json
"speakingCycle": {
  "enabled": true,
  "initialForwardDuration": 3.0,
  "reverseDuration": 2.0,
  "forwardDuration": 2.0
}
```
- Creates dynamic talking animation: plays forward for N seconds, then cycles reverse/forward

---

## Key Modules

### Avatar Video System
- **AvatarManager** (`avatar-manager.js`): State-based video playback
- States: `idle`, `listening`, `speaking`
- Micro-palindrome mode for smooth transitions

### WebSocket Flow
1. Frontend ‚Üí Backend (port 8080)
2. Backend ‚Üí Gemini API (with OAuth token)
3. Bidirectional streaming
4. Backend = secure proxy (adds auth, rate limiting)

### Audio Pipeline
- Input: 16kHz PCM16 ‚Üí Gemini 2.5 Flash Live
- Output: 24kHz PCM16 ‚Üê Gemini 2.5 Flash Live
- Native audio streaming (low latency, high quality)
- AudioWorklet for processing

---

## Testing

### Manual Testing
```bash
# Start backend
python backend/main.py

# Start frontend (separate terminal)
cd frontend && python -m http.server 8000

# Or use quick start
START.bat
```

### Test Checklist
- [ ] Backend starts without errors
- [ ] Frontend loads, no console errors
- [ ] Avatar video shows idle state
- [ ] Connection flow works
- [ ] Audio input/output functional
- [ ] No token leaks in logs

---

## Common Tasks

### Adding a New Feature
1. Check if config option needed ‚Üí add to `config.json`
2. Create manager class if complex (e.g., `FeatureManager`)
3. Initialize in `initializeConfigDependentComponents()`
4. Wire up UI in `index.html` and event handlers in `script.js`
5. Test thoroughly, no summary docs

### Fixing a Bug
1. Identify root cause
2. Fix the code
3. Test the fix
4. Commit with clear message
5. **DO NOT create fix summary document**

### Adding Configuration
1. Add to `config.json` with sensible default
2. Access via `AppConfig.get('path.to.setting', defaultValue)`
3. Document in code comments if complex

---

## Debugging

### Backend Issues
- Check logs for `‚ùå` markers
- Verify port 8080 not in use: `netstat -ano | findstr :8080`
- Token format: Must start with `ya29.`
- Check `ALLOWED_ORIGINS` environment variable

### Frontend Issues
- Open DevTools Console (F12)
- Look for connection errors
- Verify `config.json` loads successfully
- Check Network tab for WebSocket status

### Avatar Video Issues
- Check browser console for video load errors
- Ensure video paths in `config.json` are correct

---

## Git Workflow

### Commit Messages
```
Format: <type>: <description>

Types:
  feat: New feature
  fix: Bug fix
  refactor: Code refactoring
  perf: Performance improvement
  security: Security fix
  chore: Maintenance task
  docs: Documentation only

Example:
  security: remove token logging from backend
  feat: add micro-palindrome avatar transitions
  fix: resolve WebSocket reconnection issue
```

### What to Commit
- ‚úÖ Code changes
- ‚úÖ Configuration updates
- ‚úÖ Test files
- ‚ùå Summary documents or reports
- ‚ùå Temporary diagnostic files
- ‚ùå Personal notes

---

## File Naming Conventions

- Configuration: `config.json`, `.env`
- Managers: `*-manager.js` (kebab-case)
- Tests: `test_*.py`, `*_test.js`
- Batch files: `UPPERCASE.bat`
- Documentation: `UPPERCASE.md` (only essential docs)

---

## Dependencies

### Backend (Python)
```
websockets>=12.0
```

### Frontend (JavaScript)
- Material Design 3 Web Components (CDN)
- No build step, runs in browser

---

## Environment Variables

```bash
# Backend
BACKEND_PORT=8080
BACKEND_HOST=0.0.0.0
DEBUG=false
ALLOWED_ORIGINS=http://localhost:8000,http://localhost:8080

# Not used - tokens from user input
# PROJECT_ID in config.json
```

---

## Video Files

Located in `media/video/`:

**Customization:** Update paths in `config.json` ‚Üí `video.sources`

---

## Project Specific Notes

### Why No Summary Docs?
- User tracks work via git commits
- Reduces file clutter
- Focus on code, not meta-documentation
- Clear git history is sufficient

### When Documentation IS Needed
- Critical security vulnerability discovered
- Major architecture change affecting multiple systems
- Breaking API changes
- User specifically requests documentation

---

## Quick Reference

### Start Development
```bash
START.bat  # Easiest - auto-starts everything
```

### Get OAuth Token
```bash
gcloud auth print-access-token
```

### Check Backend Status
```bash
netstat -ano | findstr :8080
```

### View Logs
- Backend: Terminal where `python backend/main.py` runs
- Frontend: Browser DevTools Console (F12)

---

## Remember

1. **Never create summary documents** for routine work
2. **Always validate OAuth tokens** before use
3. **Use config.json** for all settings
4. **Test thoroughly** after changes
5. **Keep it simple** - don't over-engineer
6. **Security first** - no token logging ever

---

**Project Status:** 100% SDK Compliant - Complete Overhaul (Nov 2025)
**Primary Goal:** Pure SDK implementation of Gemini Live Avatar

---

## üÜï SDK Compliance Reference (Nov 2025)

### Official Google Gen AI SDK
- **Documentation**: https://googleapis.github.io/python-genai/
- **GitHub**: https://github.com/googleapis/python-genai
- **PyPI**: https://pypi.org/project/google-genai/
- **Version**: 1.51.0 (Latest as of Nov 18, 2025)

### Critical SDK Method Signatures

**send_realtime_input** - for audio/video:
```python
await session.send_realtime_input(
    audio=types.Blob(data=bytes, mime_type="audio/pcm")  # Named parameter!
)
```

**send_client_content** - for text/images:
```python
await session.send_client_content(
    turns=types.Content(role="user", parts=[...]),  # turns= not content=!
    turn_complete=True  # turn_complete= not end_of_turn=!
)
```

**send_tool_response** - for function results:
```python
await session.send_tool_response(
    function_responses=[...]  # function_responses= parameter!
)
```

### SDK Configuration Pattern (OFFICIAL)
```python
# CORRECT: Always use snake_case for ALL parameters
config = types.LiveConnectConfig(
    response_modalities=["AUDIO"],        # snake_case
    speech_config=types.SpeechConfig(     # snake_case
        voice_config=types.VoiceConfig(   # snake_case
            prebuilt_voice_config=types.PrebuiltVoiceConfig(  # snake_case
                voice_name="Puck"
            )
        )
    ),
    system_instruction=types.Content(     # snake_case
        role="user",
        parts=[types.Part(text="...")]
    )
)
```

**Official Reference**: https://googleapis.github.io/python-genai/

### SDK Warnings
‚ö†Ô∏è **Do not interleave `send_client_content` and `send_realtime_input` in the same turn** - can cause unexpected results
